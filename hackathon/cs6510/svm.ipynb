{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import sys\n",
    "from sklearn.impute import SimpleImputer\n",
    "import random\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_train():\n",
    "    train = pd.read_csv(\"train.csv\")\n",
    "\n",
    "    train = train[~(train['num_of_cancelled_trips'] >= 6)]\n",
    "    train = train[~(train['anon_var_1'] >=115)]\n",
    "    train = train[~(train['anon_var_2'] >= 70)]\n",
    "    train = train[~(train['anon_var_3'] >= 110 )]\n",
    "    train = train[~(2>train['customer_score'])]\n",
    "    train = train[~(train['customer_score']>=3.7 )]\n",
    "#     print(train.columns)\n",
    "    return train\n",
    "\n",
    "def hotenc(train):\n",
    "    mf1 = pd.get_dummies(train['taxi_type'])\n",
    "    train = train.drop('taxi_type',axis = 1)\n",
    "    train = train.join(mf1,rsuffix='_Taxitype')\n",
    "\n",
    "    mf2 = pd.get_dummies(train['customer_score_confidence'])\n",
    "    train = train.drop('customer_score_confidence',axis = 1)\n",
    "    train = train.join(mf2,rsuffix='_Customerscore_confidence')\n",
    "\n",
    "    mf = pd.get_dummies(train['drop_location_type'])\n",
    "    train = train.drop('drop_location_type',axis = 1)\n",
    "    train = train.join(mf,rsuffix='_drop_location_type')\n",
    "\n",
    "    mf = pd.get_dummies(train['sex'])\n",
    "    train = train.drop('sex',axis = 1)\n",
    "    train = train.join(mf,rsuffix='sex')\n",
    "    mf = train['anon_var_1'].isnull()\n",
    "    mf =mf.astype(int)\n",
    "    print (mf)\n",
    "    train = train.join(mf,rsuffix= 'anon_var_1_presence')\n",
    "    return train\n",
    "\n",
    "def imputer(data,test):\n",
    "    \n",
    "    imp_mean1 = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    imp_mean2 = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    imp_median = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "\n",
    "    \n",
    "    dat = np.array(data[\"customer_score\"])\n",
    "    imp_mean1.fit(np.resize(dat,(len(dat),1)))\n",
    "    dat = imp_mean1.transform(np.resize(dat,(len(dat),1)))\n",
    "    data[\"customer_score\"] = dat\n",
    "#     print(data.isna().sum())\n",
    "\n",
    "    \n",
    "    dat = np.array(test[\"customer_score\"])\n",
    "    dat = imp_mean1.transform(np.resize(dat,(len(dat),1)))\n",
    "    test[\"customer_score\"] = dat\n",
    "#     print(test.isna().sum())\n",
    "\n",
    "    dat = np.array(data[\"anon_var_1\"])\n",
    "    imp_mean2.fit(np.resize(dat,(len(dat),1)))\n",
    "    dat = imp_mean2.transform(np.resize(dat,(len(dat),1)))\n",
    "    data[\"anon_var_1\"] = dat\n",
    "#     print(data.isna().sum())\n",
    "    \n",
    "    \n",
    "    \n",
    "    dat = np.array(test[\"anon_var_1\"])\n",
    "    dat = imp_mean1.transform(np.resize(dat,(len(dat),1)))\n",
    "    test[\"anon_var_1\"] = dat\n",
    "    \n",
    "    \n",
    "    dat = np.array(data[\"months_of_activity\"])\n",
    "    imp_median.fit(np.resize(dat,(len(dat),1)))\n",
    "    dat = imp_median.transform(np.resize(dat,(len(dat),1)))\n",
    "    data[\"months_of_activity\"] = dat\n",
    "#     print(data.isna().sum())\n",
    "    \n",
    "    \n",
    "    \n",
    "    dat = np.array(test[\"months_of_activity\"])\n",
    "    dat = imp_median.transform(np.resize(dat,(len(dat),1)))\n",
    "    test[\"months_of_activity\"] = dat\n",
    "\n",
    "    \n",
    "#     print(test)\n",
    "    return data, test\n",
    "\n",
    "def boxCoxTransform(train, test):\n",
    "  \n",
    "    xt, _ = stats.boxcox(train[\"anon_var_2\"])\n",
    "    xte = stats.boxcox(test[\"anon_var_2\"],lmbda = _)\n",
    "    train[\"anon_var_2\"] = (xt-xt.mean())/xt.std()\n",
    "    test[\"anon_var_2\"] = (xte-xt.mean())/xt.std()\n",
    "    \n",
    "    xt, _ = stats.boxcox(train[\"distance\"])\n",
    "    xte = stats.boxcox(test[\"distance\"],lmbda = _)\n",
    "    train[\"distance\"] = (xt-xt.mean())/xt.std()\n",
    "    test[\"distance\"] = (xte-xt.mean())/xt.std()\n",
    "    \n",
    "    xt, _ = stats.boxcox(train[\"customer_score\"])\n",
    "    xte = stats.boxcox(test[\"customer_score\"],lmbda = _)\n",
    "    train[\"customer_score\"] = (xt-xt.mean())/xt.std()\n",
    "    test[\"customer_score\"] = (xte-xt.mean())/xt.std()\n",
    "\n",
    "    xt, _ = stats.boxcox(train[\"ratings_given_by_cust\"])\n",
    "    xte = stats.boxcox(test[\"ratings_given_by_cust\"],lmbda = _)\n",
    "    train[\"ratings_given_by_cust\"] = (xt-xt.mean())/xt.std()\n",
    "    test[\"ratings_given_by_cust\"] = (xte-xt.mean())/xt.std()\n",
    "    \n",
    "    xt, _ = stats.boxcox(train[\"anon_var_1\"])\n",
    "    xte = stats.boxcox(test[\"anon_var_1\"],lmbda = _)\n",
    "    train[\"anon_var_1\"] = (xt-xt.mean())/xt.std()\n",
    "    test[\"anon_var_1\"] = (xte-xt.mean())/xt.std()\n",
    "\n",
    "    \n",
    "    xt, _ = stats.boxcox(train[\"anon_var_3\"])\n",
    "    xte = stats.boxcox(test[\"anon_var_3\"],lmbda = _)\n",
    "    train[\"anon_var_3\"] = (xt-xt.mean())/xt.std()\n",
    "    test[\"anon_var_3\"] = (xte-xt.mean())/xt.std()\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        1\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        1\n",
      "5        1\n",
      "6        1\n",
      "7        1\n",
      "8        0\n",
      "9        1\n",
      "10       0\n",
      "11       1\n",
      "12       0\n",
      "13       0\n",
      "14       1\n",
      "15       0\n",
      "16       0\n",
      "17       0\n",
      "18       0\n",
      "19       1\n",
      "20       1\n",
      "21       1\n",
      "22       1\n",
      "23       1\n",
      "24       0\n",
      "25       0\n",
      "26       1\n",
      "27       0\n",
      "28       1\n",
      "29       1\n",
      "        ..\n",
      "78967    0\n",
      "78968    0\n",
      "78969    1\n",
      "78970    0\n",
      "78971    0\n",
      "78972    1\n",
      "78973    0\n",
      "78974    1\n",
      "78975    1\n",
      "78976    1\n",
      "78977    1\n",
      "78978    1\n",
      "78979    0\n",
      "78980    0\n",
      "78981    1\n",
      "78982    1\n",
      "78983    1\n",
      "78984    1\n",
      "78985    1\n",
      "78986    1\n",
      "78987    1\n",
      "78988    0\n",
      "78989    0\n",
      "78990    0\n",
      "78991    1\n",
      "78992    0\n",
      "78993    1\n",
      "78994    1\n",
      "78995    1\n",
      "78996    0\n",
      "Name: anon_var_1, Length: 77673, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_data = read_train()\n",
    "train_data = hotenc(train_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        1\n",
      "1        1\n",
      "2        1\n",
      "3        0\n",
      "4        0\n",
      "5        0\n",
      "6        1\n",
      "7        0\n",
      "8        1\n",
      "9        1\n",
      "10       0\n",
      "11       0\n",
      "12       1\n",
      "13       1\n",
      "14       1\n",
      "15       1\n",
      "16       1\n",
      "17       1\n",
      "18       0\n",
      "19       1\n",
      "20       0\n",
      "21       1\n",
      "22       0\n",
      "23       1\n",
      "24       1\n",
      "25       1\n",
      "26       1\n",
      "27       0\n",
      "28       0\n",
      "29       1\n",
      "        ..\n",
      "52635    1\n",
      "52636    1\n",
      "52637    1\n",
      "52638    0\n",
      "52639    0\n",
      "52640    1\n",
      "52641    1\n",
      "52642    0\n",
      "52643    1\n",
      "52644    0\n",
      "52645    1\n",
      "52646    1\n",
      "52647    1\n",
      "52648    0\n",
      "52649    0\n",
      "52650    1\n",
      "52651    1\n",
      "52652    0\n",
      "52653    1\n",
      "52654    1\n",
      "52655    1\n",
      "52656    1\n",
      "52657    0\n",
      "52658    0\n",
      "52659    0\n",
      "52660    0\n",
      "52661    0\n",
      "52662    1\n",
      "52663    1\n",
      "52664    1\n",
      "Name: anon_var_1, Length: 52665, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv(\"test.csv\")\n",
    "test_data = hotenc(test_data)\n",
    "# train_data, test_data = imputer(train_data,test_data)\n",
    "# train_data, test_data = boxCoxTransform(train_data,test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train,data_test = train_test_split(train_data, test_size=0, shuffle = True)\n",
    "\n",
    "# data_train, data_test = imputer(data_train,data_test)\n",
    "# data_train, data_test = boxCoxTransform(data_train,data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 35)\n",
      "Index(['id', 'distance', 'months_of_activity', 'customer_score',\n",
      "       'ratings_given_by_cust', 'num_of_cancelled_trips', 'anon_var_1',\n",
      "       'anon_var_2', 'anon_var_3', 'pricing_category', 'A', 'B', 'C', 'D', 'E',\n",
      "       'A_Customerscore_confidence', 'B_Customerscore_confidence',\n",
      "       'C_Customerscore_confidence', 'A_drop_location_type',\n",
      "       'B_drop_location_type', 'C_drop_location_type', 'D_drop_location_type',\n",
      "       'E_drop_location_type', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N',\n",
      "       'Female', 'Male', 'anon_var_1anon_var_1_presence'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data_test.shape)\n",
    "print(data_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm(training_data,testing_data):\n",
    "    ytrain = training_data[\"pricing_category\"]\n",
    "    xtrain = training_data.drop(\"pricing_category\",axis = 1)\n",
    "    xtrain = xtrain.drop(\"id\",axis = 1)\n",
    "    \n",
    "    ytest = testing_data[\"pricing_category\"]\n",
    "    xtest = testing_data.drop(\"pricing_category\",axis = 1)\n",
    "    xtest = xtest.drop(\"id\",axis = 1)\n",
    "    \n",
    "    \n",
    "#     clf = LinearSVC(random_state=0, tol=1e-5 ,max_iter = 10000)\n",
    "#     clf.fit(xtrain, ytrain)\n",
    "\n",
    "    polynomial_svm = SVC( kernel = \"poly\",degree = 2,coef0 = 1, gamma = 1)\n",
    "\n",
    "    polynomial_svm.fit(xtrain,ytrain)\n",
    "\n",
    "    outcome = clf.predict(xtest)\n",
    "    \n",
    "    \n",
    "\n",
    "    accuracy = accuracy_score(ytest,outcome)\n",
    "    print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm(data_train,data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(training_data,testing_data):\n",
    "    ytrain = training_data[\"pricing_category\"]\n",
    "    xtrain = training_data.drop(\"pricing_category\",axis = 1)\n",
    "    xtrain = xtrain.drop(\"id\",axis = 1)\n",
    "    \n",
    "    ytest = testing_data[\"pricing_category\"]\n",
    "    xtest = testing_data.drop(\"pricing_category\",axis = 1)\n",
    "    xtest = xtest.drop(\"id\",axis = 1)\n",
    "    \n",
    "    \n",
    "    clf = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(10, 3), random_state=1)\n",
    "    clf.fit(xtrain, ytrain)\n",
    "\n",
    "    #     polynomial_svm = SVC(C = c, kernel = \"poly\",degree = deg,coef0 = 1, gamma = 1)\n",
    "\n",
    "    #     polynomial_svm.fit(x,y)\n",
    "    \n",
    "    outcome = clf.predict(xtest)\n",
    "    \n",
    "    \n",
    "\n",
    "    accuracy = accuracy_score(ytest,outcome)\n",
    "    print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp(data_train,data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xg(training_data,testing_data):\n",
    "    ytrain = training_data[\"pricing_category\"]\n",
    "    xtrain = training_data.drop(\"pricing_category\",axis = 1)\n",
    "    xtrain = xtrain.drop(\"id\",axis = 1)\n",
    "    \n",
    "    ytest = testing_data[\"pricing_category\"]\n",
    "    xtest = testing_data.drop(\"pricing_category\",axis = 1)\n",
    "    xtest = xtest.drop(\"id\",axis = 1)\n",
    "    clf = XGBClassifier(nthread=-1,max_depth = 4, learning_rate=0.01,n_estimators=500,subsample=0.77,colsample_bynode=0.75,verbosity = 0)\n",
    "    \n",
    "    clf.fit(xtrain, ytrain)\n",
    "\n",
    "    #     polynomial_svm = SVC(C = c, kernel = \"poly\",degree = deg,coef0 = 1, gamma = 1)\n",
    "\n",
    "    #     polynomial_svm.fit(x,y)\n",
    "    \n",
    "    outcome = clf.predict(xtest)\n",
    "    \n",
    "    \n",
    "\n",
    "    accuracy = accuracy_score(ytest,outcome)\n",
    "    print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.699130994528484\n"
     ]
    }
   ],
   "source": [
    "xg(data_train,data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
